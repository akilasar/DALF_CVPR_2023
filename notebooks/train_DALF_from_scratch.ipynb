{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzX8UHSfbtEv9AVqTi09Oa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Setup environment"],"metadata":{"id":"y_TxsEsrhtzg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0omGcpT6TuF"},"outputs":[],"source":["#Clone DALF repo\n","%cd /content\n","!git clone 'https://github.com/verlab/DALF_CVPR_2023.git'\n","%cd /content/DALF_CVPR_2023\n","import sys\n","sys.path.append('/content/DALF_CVPR_2023')\n","\n","#Install kornia dependency\n","!pip install kornia"]},{"cell_type":"markdown","source":["# Get datasets from 1DSfM project\n","In this example we use only a fraction of the images, please uncomment the last line to obtain all images, it should more time (about 10-15 minutes)."],"metadata":{"id":"UPsDEjMS7TvI"}},{"cell_type":"code","source":["from modules.dataset import getdata\n","\n","#Get Sample dataset to be faster\n","getdata.retrieve(data_path = './dataset', reduced = True)\n","\n","#If you want FULL DATASET, PLEASE USE THE BELOW COMMAND TO OBTAIN ALL DATASETS\n","#getdata.retrieve(data_path = './nonrigid-keypoint-detector-descriptor/dataset', reduced = False)"],"metadata":{"id":"KxJdsj_V6nsd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train the network\n","Please notice that training entirely on Colab would require **more than a day** of training with the free GPU tier. You can train locally with your GPU."],"metadata":{"id":"G2tPNtCG-AJm"}},{"cell_type":"code","source":["# Load the TensorBoard notebook extension to monitor our training\n","!mkdir './logdir'\n","%load_ext tensorboard\n","%tensorboard --logdir \"./logdir\""],"metadata":{"id":"rkPK1tj8BPoF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## First-stage training\n","Here, we train the backbone and detector, without the deformation-aware module. Please refer to the [paper](https://arxiv.org/abs/2304.00583) for more details."],"metadata":{"id":"3bikeeUd-DLw"}},{"cell_type":"code","source":["#Now lets train first stage!\n","! python3 train.py --mode \"ts1\" --datapath \"./dataset/*/images/*.jpg\" --logdir \"./logdir\" --save \"./logdir\" #--dry_run"],"metadata":{"id":"GZsbwVeG93Nu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Second-stage training\n","In second stage, backbone is frozen and WarperNet alongside the detector decoder are optimized to refine detections and account for strong deformations. The fusion module is also optimized to optimally fuse the distinct and invariant descriptors."],"metadata":{"id":"6zLNJKna-Ith"}},{"cell_type":"code","source":["#Now lets train second stage!\n","\n","saved_model=\"./logdir/model_ts1_80000_final.pth\"\n","\n","#saved_model=\"./logdir/model_ts1_1000_final.pth\" #Used as a quick test with --dry_run in the first training stage\n","\n","! python3 train.py --mode \"ts-fl\" --datapath \"./dataset/*/images/*.jpg\" --logdir \"./logdir\" --pretrained $saved_model --save \"./logdir\""],"metadata":{"id":"7KRhgkzs-Mfx"},"execution_count":null,"outputs":[]}]}